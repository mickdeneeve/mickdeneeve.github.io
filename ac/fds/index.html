<html>
<head>
<title>Hypernymy recognition in a neural distributional model using information gain and
  update semantics</title>
</head>
<body>
<h1><center>Hypernymy recognition in a neural distributional model using information gain and update semantics<center></h1>
<h3><center>Mick de Neeve<br><br>Department of Philosophy<br>University of Amsterdam<br><br>December 23, 2022</center></h3>
<b>Abstract </b> While similarity relations can be easily identified in dis-
tributional models, hypernymy is harder because the relationship is
asymmetric. Information gain has been proposed as a measure, but
it is not straightforward how to use this in neural models because
word co-occurences are implicit. This paper presents a method to
nonetheless measure it in a (neural) Word2Vec model, but it has an
additional aim: to show update semantics is a viable candidate for
the underlying notion of meaning in distributional models. To this
end, an epistemic dynamic semantics is implemented using the neural
network, with updates between hypernymic information states. The
result confirms information gain experiments to a signicant degree,
and outperforms it on a small subset of transitivity triples.
<ul>
  <li><a href="deneeve.updsemdist.pdf" target="_blank">Full text (pdf)</a></li>
  <br>
  <li><a href="src/">Source code</a></li>
  <li><a href="lex/">Datasets</a></li>
  <li><a href="exp/">Results</a></li>
  <br>
  <li><a href="https://github.com/RaRe-Technologies/gensim" target="_blank">Model (Gensim/Word2Vec)</a></li>
  <li><a href="https://www.litika.com/torrents/enwiki-20210920-pages-articles.xml.bz2.torrent" target="_blank">Corpus (Wikipedia torrent)</a></li>
</ul> 
</body>
</html>
